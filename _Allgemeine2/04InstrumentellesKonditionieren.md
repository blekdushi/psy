---
layout: page
title: Instrumentelles Konditionieren
full_title: 
published: true
vo: Allgemeine Psychologie 2
vortragender: Job
semester: 2025S
---

{% include allgemeine2_disclaimer.html %}


# Instrumentelles Konditionieren

> The process whereby organisms learn to make or to refrain from making certain responses in order to obtain or avoid certain outcomes.

Der große Unterschied zum klassichen Konditionieren ist, dass beim instrumentellen Konditionieren das Ergebnis/der Outcome vom gezeigten Verhalten abhängig ist. Beim klassischen Konditionieren beeinflusst die konditionierte Reaktion CR den Outcome jedoch nicht.

Die Dressur von Tieren wird schon seit Jahrhunderten praktiziert, aber Thorndike hat mit Katzen in der **puzzle box** das Erlernen von Verhalten systematisch erforscht. Erst wenn die Katzen ein bestimmtes Verhalten zeigten (z.B. Ziehen an einer Schnur), öffnete sich die Tür und die Katze konnte zum Futter gelangen. Die ersten Male hat die Katze eher zufällig das richtige Verhalten gezeigt. Nach wenigen Trials zeigte sie das Verhalten dann sehr schnell bzw. umgehend. Thorndike fasste diese Beobachtung als **law of effect** zusammen: Zeigt ein Organismus in einer bestimmten Reizsituation (diskriminatives Stimulus - _Sd_) ein bestimmtes Verhalten (Response - _R_), dann zeigt sich ein bestimmtes Ergebnis (Outcome - _O_ bzw. Consequence - _C_). Formal geschrieben _Sd # R # O_ , wobei das Rautensymbol # sowas  wie "gefolgt von" bedeutet und des diskriminative Stimulus _Sd_ wie folgt definiert ist:

> In operant conditioning, a stimulus indicating that a particular response (R) may lead to a particular outcome (O).

Thorndike ging davon aus, dass der Organismus eine direkte Assoziation von _Sd # R_ erlernt, und dass _O_ diese Beziehung verstärkt. Dagegen spricht das **Verstärker-Devaluations-Paradigma**: Man hat Ratten für den diskriminativen Stimulus _Sd_ zwei Responses angelernt _R1_ führte zu Futter und _R2_ führte zu Saft. Dann hat man über das Futter Übelkeit induziert und die Ratten zeigten nur noch _R2_. Ein Indiz dafür, dass die Assziation zwischen _R_ und _O_ erlernt wird. Ebenfalls für die Relation _Sd # R # O_ spricht, dass wenn eine Sättigung eingetreten ist, die _R_ bei Vorhandensein von _Sd_ nicht gezeigt wird. Diese Überlegungen und Unterscheidungen wird wichtig, wenn man Gewohnheiten »habits« definieren und von erlerntem Verhalten, das gezielt wegen eines erwarteten _O_ gezeigt wird, abgrenzen möchte.

Beim **Diskriminationslernen** lernt ein Organismus, dass eine Response nur unter gewissen Umständen zum Outcome führt. Der Reiz, der anzeigt, dass eine _R_ im aktuellen Kontext **nicht** zu _O_ führt, ist der Delta-Stimulus _SΔ_. Über **graduelles Training** können schwierige Reizdiskriminationen schrittweise erlernt werden. Zum Beispiel haben in einem Versuch Tauben Kreissymbole mit vertikalen Linien nicht von jenen mit horizontalen Linien unterscheiden können. Man hat dann die Kreissymbole mit roter und grüner Hintergrundfarbe versehen. Bei jedem Trial hat man die Farben mit weniger Deckkraft präsentiert, solange bis die Farben ganz verschwunden waren. Die Tauben konnten nun die Kreissymbole voneinander unterscheiden.

Das Verhalten _R_ kann mittels **Shaping** sehr präzise gesteuert werden:
> An operant conditioning technique in which successive approximations to the desired response are reinforced.
Zunächst verstärkt man jedes Verhalten, dass dem gewünschten näher kommt. Danach verstärkt man nur noch jenes, das dem gewünschten noch näher kommt, solange bis auch feinste Nuancen von Verhalten unterschieden werden können.

Mittels **Chaining** kann man dann Verhalten zu komplexeren Handlungsabfolgen aneinanderreihen:
> An operant conditioning technique in which organisms are gradually trained to execute complicated sequences of discrete responses.
Dabei erzeugt ein Outcome _O_ eine neuen Situation, die als diskriminative Reiz _Sd_ für eine andere erlernte Verhaltensweise dient. 

Es gibt verschiedene Typen von **Verstärkern**:
* Primäre Verstärker (Essen, Sex...)
* Materielle Verstärker (Geld, Spielsachen...)
* Soziale Verstärker (Lob, Anerkennung...)
* Aktivitätsbezogene Verstärker (Achterbahn...)
* Informative Verstärker (Erkenntnis, Information...)

**Sekundäre Verstärker** sind Verstärker, die a priori neutral sind, z.B. Geld. Sie werden erst dann zu Verstärkern, wenn ein Organismus lernt, dass es sich dabei um diskriminative Reize _Sd_ handelt, die dann über eine Response _R_ zu einem primären Verstärker _O_ führen, so wie oben beim _Chaining_ beschrieben.
> A reinforcer that initially has no biological value but that has been paired with (or predicts the arrival of) a primary reinforcer.

Eine weitere Einteilung ist, ob es sich um eine Belohnung oder Bestrafung handelt und ob diese durch Herstellen oder Beenden eines angenehmen oder aversiven Zustandes entsteht:

| | Angenehmer Reiz | Unangenehmer Reiz
| :- | :-: | :-:
Outcome erzeugt Reiz | Positive Verstärkung (Belohnung) ↑ <br>_»positive reinforcement«_ | Bestrafung 1. Art ↓ <br>_»positive punishment«_
Outcome beendet Reiz | Bestrafung 2. Art ↓ <br>_»negative punishment«_ | Negative Verstärkung (Flucht / Vermeidung) ↑ <br>_»negative reinforcement«_

Bestrafung ist nicht einfach nur das Gegenteil von Belohnung. Während Belohnung primär dazu dient, erwünschtes Verhalten zu verstärken, ist die Hauptfunktion der Bestrafung die Unterdrückung unerwünschten Verhaltens.

|Effekt|Erklärung
| :- | :- |
|Exploration und Variabilität| Nach einer Bestrafung zeigt der Organismus variables, exploratives Verhalten, da er nach alternativen, unbelasteten Verhaltensformen sucht.
|Kontext-Sensitivität ("Cheating")|Bestrafung ist stark an diskriminative Reize gebunden. Ändert sich der Kontext oder die Umgebung, tritt das bestrafte Verhalten häufig wieder auf (Cheating). Das Tier oder der Mensch nimmt an, dass die Bestrafung in der neuen Situation ausbleibt.
|Geringere Wirksamkeit | Wenn ein Verhalten gleichzeitig belohnt (z.B. Anerkennung der Mitschüler) und bestraft (Tadel des Lehrers) wird, wirkt die Belohnung oft stärker.
|Intensität und Gewöhnung | Bestrafung ist am effektivsten, wenn sie sofort und mit hoher Intensität einsetzt. Eine anfänglich milde Bestrafung begünstigt einen Gewöhnungseffekt (Habituation), wodurch selbst eine spätere, heftigere Bestrafung wirkungslos bleiben kann.

Beim Menschen kommen zu den Lernprozessen noch komplexe, soziale und ethische Probleme hinzu:
* Verhinderung von Einsicht: Bestrafung verschleiert oft, warum ein Verhalten unerwünscht ist, und verhindert so die intrinsische Überzeugung, das Verhalten zukünftig zu meiden.
* Beziehungsschaden: Die Beziehung zwischen dem Strafenden und dem Bestraften leidet stark unter dem Einsatz von Bestrafung.
* Schlechte Vorbildfunktion: Bestrafung vermittelt die Botschaft, dass Aggression oder Zwang ein legitimes Mittel zur Konfliktlösung und Verhaltenssteuerung sind. 

Eine effektivere Möglichkeit um unerwünschstes Verhalten zu verhindern ist die differentielle Verstärkung alternativen Verhaltens. Zum Beispiel hat ein Kino eine App herausgebracht, die man zu Beginn des Films einschaltet und registriert, ob man während des Films das Smartphone verwendet. Wenn nicht, dann wird man mit Gutscheinen belohnt. Das soll verhindern, dass Besucher während des Films das Smartphone verwenden und andere Besucher stören.
> Differential reinforcement of alternative behaviors (DRA) is a method used to decrease the frequency of unwanted behaviors by instead reinforcing preferred alternative behaviors.

Auch bei der Belohnung hat die **Intensität** der Verstärker einen Einfluss auf das Lernen. Ratten laufen schneller durch ein Labyrinth, wenn es mehr Futter als Belohnung gibt und Ratten vermeiden ein Verhalten umso eher desto stärker der bestrafende Stromstoß ist.

Der Organismus lernt nicht nur, _dass_ es einen Verstärker gibt, sondern auch _welchen_. Die Wichtigkeit der **Identität** des Verstärkers zeigt sich bei der Beobachtung des **negativen Kontrasts**: Ratten bevorzugen Zuckerwasser gegenüber einfachem Futter. Wenn sie ein Verhalten gelernt haben, weil sie mit Zuckerwasser belohnt wurden und dann plötzlich für das Verhalten "nur" mit Futter belohnt werden, dann sinkt die Verhaltensfrequenz umgehend und deutlich, weil sie eine bessere Belohnung erwartet hatten.

Wie oft und wie regelmäßig ein Verhalten verstärkt wird (**Verstärkerpläne**) hat ebenso Einfluss auf die erlernte Assoziation. Unter **kontinuierlicher Verstärkung** versteht man, dass jedes Auftreten des Verhaltens verstärkt wird. Dabei lernt der Organismus sehr schnell, aber das Verhalten wird auch rasch wieder gelöscht, wenn die Verstärkung ausbleibt. Löschresistenter ist die **intermittierende Verstärkung** bei der das Verhalten nur ab und zu verstärkt wird.
Beim **Quotenplan** verstärkt man nicht jedes Verhalten, sondern nur jedes x-te Mal.
Beim **Intervallplan** verstärkt man nicht jedes Verhalten, sondern immer nur das erste innerhalb einer bestimmten Zeitspanne.
Beide Pläne können entweder **konstant** sein, wenn Intervall und Quote streng eingehalten werden, oder **variablel** wenn Quote und Intervall nur einen Mittelwert angeben und tatsächliche Quote und Intervall zufällig variieren.

Bei fixen Plänen zeigt sich nach einer Belohnung ein Pausieren des Verhaltens (»post-reinforcement pause«), bei variablen Plänen nicht. Der Organismus scheint das Muster hinter fixen Plänen zu erkennen. Bei Quotenplänen wird das Verhalten in kürzerer Zeit häufiger gezeigt als bei Intervallplänen, da der Organismus durch die Haufigkeit des Verhaltens die nächste Belohnung selbst herbeiführen kann.

Bisher wurde davon ausgegangen, dass eine klare Kontingenz (ein ursächlicher Zusammenhang) zwischen einem Verhalten und dessen Konsequenz (Verstärker oder Bestrafung) bestehen muss. Wenn diese Kontingenz fehlt – wenn die Konsequenz zufällig auftritt – kann dies zukünftiges Lernen blockieren und zu einem Zustand der erlernten Hilflosigkeit führen. Ein Experiment mit Ratten illustriert diesen Effekt:
* Phase 1 (Basis): Beide Gruppen von Ratten lernten, einen Hebel zu drücken, um Futter zu erhalten.
* Phase 2 (Vorbehandlung): Die Versuchsgruppe erhielt nun zufällige Stromschläge, die nicht mit ihrem Verhalten (Hebeldrücken) in Verbindung standen. Die Kontrollgruppe erhielt keine Schläge.
* Phase 3 (Konditionierung): Nun erhielt jede Ratte einen Elektroschock, sobald sie den Hebel drückte.
* Ergebnis: Die Kontrollgruppe verstand den Zusammenhang sofort und unterließ das Hebeldrücken schnell. Die Versuchsgruppe hingegen drückte den Hebel weiterhin. Die frühe Erfahrung mit unkontrollierbaren, zufälligen Schocks hatte bei ihnen das Lernen der neuen, kontingenten Regel blockiert.

Ein ähnlicher, aber weitreichenderer Befund wurde in einem klassischen Hunde-Experiment beobachtet:
* Gruppe 1 (Kontrollgruppe): Die Hunde erhielten Elektroschocks, konnten diesen aber durch einen Sprung auf eine andere Plattform entkommen und das Schockerlebnis beenden.
* Gruppe 2 (Versuchsgruppe): Die Hunde erhielten ebenfalls Schocks, konnten diese jedoch nicht durch eigenes Verhalten beenden (unkontrollierbare Situation).
* In der zweiten Phase des Experiments wurde für alle Hunde ein Signal eingeführt, das den Schock ankündigte, und jeder Hund hätte auf die sichere Seite springen können.
* Ergebnis: Die Hunde der Kontrollgruppe lernten schnell, dem Signal zu folgen und in Sicherheit zu springen. Die Hunde der Versuchsgruppe taten dies kaum oder gar nicht. Sie hatten in der ersten Phase gelernt, dass ihre Handlungen keinen Einfluss auf die Schocks hatten, und zeigten deshalb in der zweiten Phase kein Fluchtverhalten, obwohl es nun wirksam gewesen wäre. Dieser Zustand des passiven Ertragens wird als erlernte Hilflosigkeit bezeichnet.
* Bei Menschen konnten ähnliche Experimente zeigen, dass jene, die der unkontrollbieren Situation ausgesetzt waren, danach in Leistungsaufgaben (Anagramm lösen) schlechter waren (**generalisierte Unkontrollierbarkeitserwartung**)

Bei der Kindererziehung spielen obige Beobachtungen eine wichtige Rolle. Einige hilfreiche Strategien sind:
* adäquates Verhalten verstärken
* kontingente und konsequente Verstärkung
* Token Economy (Objekte mit Tauschwert)
* Token entziehen als Bestrafung
* Ignorieren von unangemessenem Verhalten
* Sättigung des unerwünschten Verhaltens ermöglichen/abwarten
* Time-out - Entzug von positiven Verstärkern

**Erlernte Hilflosigkeit** ist die Erfahrung, dass eigenes Verhalten keinen Effekt hat (z.B. Bestrafung nicht durch eigenes Verhalten beeinflusst werden kann), erschwert Erwerb und Ausführung neuer instrumenteller Reaktionen. Nach Seligman (1975) kann Erfahrung von Nicht-Kontingenz auf andere Aufgaben und Kontexte generalisieren (»generalisierte Unkontrollierbarkeitserwartung«). Er beschreibt drei Folgen der Erfahrung von Unkontrollierbarkeit:
* motivationales Defizit (keine Anstrengung zu fliehen)
* kognitives Defizit (verzögertes Lernen)
* emotionales Defizit (Stress, Apathie, „Depression“)

# Neuoronale Grundlagen

Dopamin ist von zentraler Bedeutung für Belohnung und Anreizmotivation. Dopaminerge Bahnen sind:
* Nigrostriatales System
* Mesolimbisches System
* Mesokortikales System

Theorien über die Rolle von Dopamin:
* **Hedonie-Hypothese**: Dopamin vermittelt positive, hedonische Gefühle. 
* **Anreiz-Hervorhebungs-Hypothese**: Dopamin erhöht die Salienz von Anreizen und das Verlangen nach Belohnung, nicht aber die Gefühle selbst.
* **Belohnungserwartungs-Hypothese**: Dopamin codiert den Belohnungs-Vorhersagefehler.

Wichtig ist zwischen dem hedonischen "Mögen" (**Liking**) und den motivationalen "Wollen" (**Wanting**) zu unterscheiden. Am Gesichtsausdruck vieler Säugetiere lässt sich schätzen, ob sie gerade Liking empfinden.

Was für die Anreiz-Hervorhebungs-Hypothese spricht, ist ein Versuch mit Ratten, bei denen man das Dopaminsystem gestört hat. Trotzdem zeigten die Ratten Liking, wenn man ihnen eine Zuckerlösung gab. Weitere Versuche zeigten, dass Dopamin eher motivationales, anreizbezogenes Wanting fördert. Die Theorie erklärt auch, dass bei regelmäßigem Drogenkonsum das hedonische Gefühl abnimmt und ausbleibt, aber das Verlangen nach der Droge hoch bleibt.

Eine Studie, welche die Aktivität dopaminerger Systeme bei Affen während der Belohnung maß, unterstützt die Belohnungserwartungs-Hypothese. Die Ergebnisse zeigten, dass die Dopaminneuronen nicht die Belohnung selbst, sondern die Differenz zwischen erwarteter und tatsächlicher Belohnung signalisieren:
* Unerwartete Belohnung: Erhielten die Affen eine plötzliche, unerwartete Belohnung, zeigten die dopaminergen Neuronen eine erhöhte Aktivität (positives Belohnungsvorhersage-Fehlersignal).
* Gelerntes Erwarten: Sobald die Affen gelernt hatten, dass ein bestimmter Reiz (z.B. ein Licht) die Belohnung ankündigt, verschob sich die erhöhte Aktivität zeitlich nach vorne – sie trat nun unmittelbar nach der Wahrnehmung des Ankündigungsreizes auf.
* Ausbleibende Belohnung: Blieb die Belohnung nach dem Ankündigungsreiz aus, kam es exakt zu dem Zeitpunkt, zu dem die Belohnung erwartet worden war, zu einem Abfall der Aktivität unter die Basislinie (negatives Belohnungsvorhersage-Fehlersignal).

Diese Befunde deuten darauf hin, dass das Dopaminsystem primär ein Lernsignal liefert: Es signalisiert nicht nur die Belohnung selbst, sondern vor allem, wann und wie stark unsere Erwartungen übertroffen oder enttäuscht werden.
