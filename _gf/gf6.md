---
layout: page
title: Skinner und das Lernen
published: true
vo: Einführung in die Grundlagenfächer der Psychologie
date: 12.11.2020
full_title: Skinner und das Lernen
vortragender: Leder
---
{% include vo_header.md %}

# Behaviorismus

Das **Lernen** ist ein Teilgebiet der allgemeinen Psychologie. Im 19. Jahrhundert war vor allem das Lernen in Bezug auf beobachtbares Verhalten im Fokus der Forschung. Man untersucht die Umstände, wie und warum Menschen neues Verhalten zeigen sowie die Gründe für häufigeres oder selteneres Auftreten.

1913 formulierte **John B. Watson** seine Ansicht wie psychologische Forschung gestaltet sein soll: _"Psychology as the Behaviorist views it"_. Er gilt als der Gründer der __behavioristischen Schule__. Ihre Entstehung muss man im Kontext des Diskurses rund um das Introspektionsproblem und die Rolle von (erblicher) Anlage (Eugenik) und Trieben verstehen. Der Behaviorismus nimmt zu diesen eine Gegenpositionen ein: er entgeht dem Introspektionsproblem dadurch das innere Erleben gar nicht erst erforschen zu wollen. Lediglich das objektiv beobachtbare Verhalten sei Gegenstand der Psychologie. Er sieht sämtliches Verhalten als erlernt und nicht oder nur minimal durch erbliche Anlagen bedingt. Er sucht nach Gesetzmäßigkeiten und sein Vorgehen ist streng naturwissenschaftlich.

**Burrhus F. Skinner** ging mit seinem _radikalen Behaviorsmus_ noch einen Schritt weiter und war der Meinung, dass Denken und Bewusstsein ebenfalls nur erlerntes Verhalten seien und somit nicht die Ursache für Verhalten sein können. Der Grund dafür Bewusstsein und Erleben bei der Forschung zu ignorieren sei also nicht, dass man dazu keinen objektiven Zugang habe, sondern dass sie nicht mal von Bedeutung seien. Skinner zählt zu den bedeutendsten Psychologen des 20. Jahrhunderts.

Behavioristen stellten an ihre Forschung den Anspruch **hoch formalisiert, systematisch, operationalisiert** und **objektiv** zu sein. Somit war ihre Forschung eher an das Labor gebunden und kognitive Prozesse wurden mangels Objektivität nicht berücksichtigt. Skinners Vorschläge die Ergebnisse seiner Forschung vom Labor in das Feld zu tragen waren z.B. die [Air-Crib](https://en.wikipedia.org/wiki/B._F._Skinner#Air_crib) für Kleinkinder und die [Teaching Machine](https://en.wikipedia.org/wiki/B._F._Skinner#Teaching_machine) für das Klassenzimmer.

# Klassisches Konditionieren

**Ivan Pawlow** entdeckte bei seinen Forschungen zur Verdauung bei Hunden, dass Reflexe (z.B. Speichelfluss bei Futter) mit beliebigen Reize konditioniert werden können (z.B. Glockenläuten). Wenn ein neutraler Reiz mehrmals kurz vor dem Reflexreiz dargeboten wird, wird die Reflexreaktion auch durch den ehemals neutralen Reiz alleine ausgelöst. Im Englischen verwendet man die Begriffe **Stimulus** (Reiz) und **Response** (Reaktion).
Den ursprünglichen Reiz (Futter) nennt man _unkonditionierten Stimulus (UCS)_, die ursprüngliche Reaktion _unkonditionierte Response (UCR)_, den zuvor neutralen Reiz nennt man _konditionierter Stimulus (CS)_ und die wenn die ursprüngliche Reaktion nur durch den CS ausgelöst wird, dann nennt man sie _konditionierte Response (CR)_. Dieses gezielte Verknüpfen von neutralen Reizen mit Reflexen nennt man __klassisches Konditionieren__.

John Watson konditionierte (ethisch fragwürdig) ein kleines Kind **little Albert** darauf Angst vor kleinen Ratten zu haben. Er benutzte dafür den "Reflex", dass Kinder bei lauten Geräuschen (UCS) Angst bekommen (UCR). Er kombinierte dazu eine "weiße Ratte" (CS), wodurch Albert Angst vor weißen Ratten bekam.

Albert hatte nicht nur Angst vor weißen Ratten, sondern auch vor weißen Stofftieren, also Reizen, die der weißen Ratte ähnlich aber nicht mit ihr identisch waren. Dieses Phänomen nennt man **Generalisierung** des konditionierten Reizes. Generalisierung kann man durch **Reizdiskriminierung** entgegenwirken: beim Konditionieren bietet man nicht nur CS und UCS sondern auch mehrmals dem CS ähnliche Reize, ohne dass diesem der UCS folgt. So lernt der Organismus die ähnlichen Reize zu unterscheiden und reagiert nur noch auf den CS (z.B. Angst vor Hund ohne Leine, keine Angst vor Hund mit Leine).

Konditionierte Reize lassen sich über **Extinktion** wieder in neutrale Reize überführen. Voraussetzung dafür ist, dass der UCS mehrmals über einen längeren Zeitraum ohne CS geboten wird. Dadurch "verlernt" der Organismus die Assoziation wieder. So ganz verlernt scheint sie aber doch nicht zu sein. Die eine erneute Konditionierung mit diesem Reiz würde viel schneller funktionieren und wenn einiges an Zeit nach der Extinktion verstrichen ist, kann es sein, dass ab und zu auf den konditionierten Reiz die konditionierte Response erfolgt (**Spontanerholung**).

# Operantes Konditionieren

Ein großer Teil von Skinners Forschung beschäftigte sich mit dem operanten Konditionieren. Den Grundstein dafür legte **Edward L. Thorndike** mit seinem **Law of effect**: Er beobachtete, dass ein Katze sich aus einem Käfig zunächst durch Zufall selbst befreit. Sperrt man sie wieder ein, befreit sie sich schneller.
Er schlussfolgert, dass man Verhalten durch _Trial and Error_ erlernt und bei angenehmen Konsequenzen öfter, bei unangenehmen dafür seltener wiederholt. Diese Theorie ist auch als **Reinforcement Theory** bekannt. Skinner ging davon aus, dass sämtliches menschliche Verhalten auf Basis dieses Mechanismus erlernt sei. Er erforschte Erlernen und die Häufigkeit von Verhalten mit Ratten und Tauben in seiner **Skinner Box**.

[Wolfgang Köhler](https://en.wikipedia.org/wiki/Wolfgang_K%C3%B6hler) kritisierte Thorndikes Annahme, dass man durch Versuch und Irrtum lerne.
Er machte Experimente mit Affen, die zeigten, dass die Affen Probleme mit Einsicht lösten (z.B. Kisten stapeln um zur Banane zu kommen).

**Operantes Konditionieren** beschäftigt sich mit den Auswirkungen von Verhalten auf die Umwelt und wie sich diese Konsequenzen auf die Häufigkeit des Verhaltens auswirken (z.B. Belohnung oder Bestrafung). Das Paar _Stimulus - Response_ wird um die dritte Komponente _Konsequenz_ erweitert, was Skinner die _Dreifachkontingenz_ (S-R-C) nennt. Im Gegensatz zum klassischen Konditionieren, geht es bei Stimulus - Response nicht um Reflexe, sondern um Umweltreize (Stimulus) und gezeigtes Verhalten (Response).

Als _Konsequenz_ sind jene Reize gemeint, die auf das Verhalten folgend wahrgenommen/dargeboten werden. Dabei unterscheidet man Verstärker und Bestrafung.

Ein **Verstärker** ist ein Reiz, der die Wahrscheinlichkeit von Verhalten erhöht. **Positive Verstärker** sind angenehme Reize, die als Reaktion auf das Verhalten dargeboten werden. Unter **negativen Verstärkern** versteht man das Wegnehmen von aversiven Reizen als Reaktion auf das Verhalten.

Eine **Bestrafung** ist ein Reiz, der die Wahrscheinlichkeit von Verhalten verringert. **Positive Bestrafung** (1. Art) sind aversive Reize, die als Reaktion auf das Verhalten dargeboten werden. Unter **negativer Bestrafung** (2. Art) versteht man das Wegnehmen von angenehmen Reizen als Reaktion auf das Verhalten.

Ob ein Organismus einen Reiz als aversiv oder angenehm empfindet kann individuell variieren und nennt man **Valenz**.

Eine Voraussetzung für das Lernen ist die **Kontingenz** von Verhalten und Reizen. Sie bezeichnet die Verlässlichkeit mit der ein Reiz (C) auf ein Verhalten (R) folgt.

Wie auch die Extinktion bei der klassischen Konditionierung kann operant konditioniertes Verhalten wieder gelöscht werden, wenn der Verstärker oder die Bestrafung nicht mehr _kontingent_ mit dem Verhalten dargeboten werden. Die Verhaltenshäufigkeit bildet sich dann wieder auf das Ausgangsniveau vor der Konditionierung zurück (**operante Löschung**).

Die Umweltreize vor Ausführung eines Verhaltens (S) können als **diskriminative Reize** dienen, wie sie auch für die klassische Konditionierung oben beschrieben wurden. Erfolgt zum Beispiel eine Belohnung (C - Futter) auf ein Verhalten (R - Scheibe picken) immer nur unter bestimmten Umständen (S - grünes Licht leuchtet), nicht aber unter anderen Umständen (S - rotes Licht leuchtet), dann wird sich auch die Verhaltenshäufigkeit an diese Umstände anpassen und das rote Licht als diskriminativer Reiz wahrgenommen.

Auch die oben beschrieben **Generalisierung** triff auf die operante Konditionierung zu: eine Taube wird auch bei hell- und dunkelgrünem Licht picken, solange diese Reize nicht diskriminiert konditioniert wurden.

Skinner hat mit seiner Skinner Box die Auswirkungen von Belohnung und Bestrafung auf Verhalten systematisch analysiert. Er verstärkte/bestrafte Verhalten nicht nur _kontinuierlich_ sondern auch _partiell_ mittels Quoten- und Intervallplänen:
Ein **Quotenplan** bedeutet, dass das Verhalten nicht jedes Mal sondern nur jede X-te (=Quote) Reaktion (R) verstärkt wird.
Ein **Intervallplan** bedeutet, dass das Verhalten (R) nur einmal innerhalb eines bestimmten Zeitintervalls verstärkt wird.

Im einfachen Fall haben diese beiden Variablen (Zeitintervall und Quote) einen _fixen_ Wert. Komplexer wird es, wenn man diese Variablen rund um einen Mittelwert _variiert_, sodass im Durchschnitt z.B. jedes fünfte Verhalten verstärkt wird, aber in manchen konkreten Fällen z.B. auch schon jedes zweite oder nur jedes neunte. Als **Forschungsergebnis** hat sich gezeigt, dass das Verhalten umso öfter gezeigt wird, desto niedriger die Quote bzw. das Intervall. Intervall- und Quotenpläne werden mit Abkürzungen beschrieben:
* FR-10 : fixed ratio - jedes 10. Mal
* FI-10 : fixed interval - alle 10 Sekunden einmal
* VR-10 : variable ratio - im Durchschnitt jedes 10. Mal
* VI-10 : variable interval = im Durschschnitt alle 10 Sekunden einmal

Die Versuche wurden zwar mit Ratten und Tauben durchgeführt, ihre Befunde konnten aber auch bei anderen Tieren und Menschen reproduziert werden. Obwohl ihre Theorien keinen Platz für Kognition, Selbstbestimmung und Emotionen ließen, verstanden Behavioristen sie als optimistisch und hofften mit ihnen den Menschen zu einem glücklicherem Leben zu befähigen.

# Kognitive Wende

Klassische und operante Konditionierung können **viele Phänomene nicht erklären**: Zum Beispiel entdeckte man, dass Ratten (1) vergiftetes Futter nicht mehr anrühren, obwohl die Bestrafung (Übelkeit) erst Stunden nach der Futtereinnahme erfolgte. Ebenfalls nicht erklärt werden konnte, dass (2) isolierte Affenjungen eine Plüschpuppe einer Drahtpuppe als Ersatzmutter vorziehen, obwohl die Drahtpuppe Futter spendete (Verstärkung) und die Plüschpuppe nicht.

Der von Behvioristen abgelehnte Gedanke, dass auch kognitive Prozesse eine Rolle beim Verhalten eines Organismus spielen, wurde zunehmend akzeptiert und leitete die **kognitive Wende ein**. [Edward Tolman](https://en.wikipedia.org/wiki/Edward_C._Tolman) entdeckte, dass Ratten, die den kürzesten Weg eines Labyrinth erlernt hatten, fast auf Anhieb den zweit kürzesten Weg fanden, sobald man den schnellsten Weg blockiert hatte. Er formulierte daraufhin die Theorie von **kognitiven Landkarten**. Ähnliche Phänomene lassen sich z.B. bei Bienen, Vögel, Eichhörnchen beobachten, nämlich dass sie sich räumliche Gegebenheiten merken, obwohl sie nie verstärkt wurden. Räumliche Landkarten sind auch beim Menschen beforscht worden: So stellten Carbon & Leder (2005) fest, dass Menschen in West- und Ostdeutschland Distanzen zwischen Städten größer einschätzten, wenn zwischen ihnen der Eiserne Vorhang verlief, als wenn die Städte auf der selben Seite des Eisernen Vorhangs waren.

[Albert Bandura](https://en.wikipedia.org/wiki/Albert_Bandura) stellte fest, dass man auch durch Beobachtung (**[Social Learning](https://en.wikipedia.org/wiki/Social_learning_theory)**) lernen kann. Ein Befund, den man mit Skinners Theorien zur Konditionierung nicht erklären konnte.

# Kontrollfragen

* Gib einen Überblick über die Entstehung des Behaviorismus!
* Wie war das Forschungsvorgehen der Behavioristen. Was waren Stärken und was die Schwächen?
* Welches Menschenbild liegt dem Behaviorismus zugrunde?
* Was ist klassische Konditionierung? Welches ethisch fragwürdige Experiment ist dazu bekannt? Von wem wurde es durchgeführt?
* Erkläre _Reizdiskriminierung_, _Generalisierung_ und _Extinktion_!
* Was bedeutet _Spontanerholung_?
* Wer legte womit den Grundstein für Skinners operante Konditionierung?
* Was verstand Skinner unter _Dreifachkontingenz_?
* Was sind Verstärkerpläne? Welche gibt es? Welches Prinzip ist essentiell für bei der Darbietung von Reizen und Verstärkern?
* Wie unterscheidet sich Bestrafung 1. Art von jener 2. Art? Was ist ausschlaggebend dafür, ob etwas eine Bestrafung ist?
* Wer kritisierte die Annehme der Behavioristen, dass man durch Trial&Error lerne? Was war sein Argument?
* Welche Phänomene konnte man mit behavioristischen Theorien nicht erklären?

# Literatur
