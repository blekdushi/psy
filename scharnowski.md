---
layout: page
title: Methodische Grundlagen wissenschaftlicher Psychologie (Scharnowski)
---
# Inhalte und Ziele der Psychologie
In der Psychologie ist der Mensch **Forschungsgegenstand** und Forscher zugleich. Daraus entstehen Herausforderungen durch individuelle Unterschiede, sowohl durch Anlage (Persönlichkeit) als auch die Situation (z.B. Tagesform). Beforscht werden:
* Wahrnehmung
* Erleben
* Verhalten
* Bewusstsein & Gedanken
* Gefühle & Wünsche

Im Gegensatz zu viele anderen Forschungsgegenständen, haben die meisten Menschen eine Meinung bzw. intuitiven Zugang zu den Fragestellungen der Psychologie ([Alltagspsychologie](https://de.wikipedia.org/wiki/Alltagspsychologie)). Die dabei verwendete Sprache ist dabei kontextabhängig, mehrdeutig und logisch nicht wohldefiniert. Ebenso zeigen sich zahlreiche Tücken, wie [Rückschaufehler](https://de.wikipedia.org/wiki/R%C3%BCckschaufehler) und das falsche Einschätzen von Wahrscheinlichkeiten.

Es braucht daher eine präzisierte **Fachsprache** für das wissenschaftliche Beschreiben eines Forschungsgegenstandes. Dabei hilft _Mathematik_ und _Logik_ (z.B. definiert das [Weber'sche Gesetz](https://de.wikipedia.org/wiki/Weber-Fechner-Gesetz#Webersches_Gesetz) die Unterschiedsschwelle in der Sinneswahrnehmung mathematisch und eindeutig). So entstehen mit der Zeit in einer Wissenschaft eine Vielzahl an Fachausdrücken. Eine logische Folge, wenn man Eindeutigkeit sicherstellen und Missverständnisse vorbeugen möchte. Was auf den ersten Blick verwirrt und im Volksmund als "fachchinesisch" bezeichnet wird, ist notwendig, damit die forschende Community eine gemeinsame Sprache hat und somit ihre Erkenntnisse kommunizieren und diskutieren kann.

**Forschungsziele** der Psychologie sind das...
1. Beschreiben,
2. Erklären,
3. Vorhersagen und
4. Verändern

...von menschlichem Erleben und Verhalten.

Beim **Beschreiben** geht es um präzises und systematisches Erfassen von Daten über den Forschungsgegenstand. Die dadurch gewonnenen Daten sollen folgende _Gütekritieren_ aufweisen:
* [Objektivität](https://de.wikipedia.org/wiki/Objektivit%C3%A4t_(Testtheorie))
* [Reliabilität](https://de.wikipedia.org/wiki/Reliabilit%C3%A4t) (Zuverlässigkeit)
* [Validität](https://de.wikipedia.org/wiki/Validit%C3%A4t) (Gültigkeit)

Ein paar Beispiele für typische Methoden sind:
* [Beobachtung](https://de.wikipedia.org/wiki/Beobachtung#Psychologie) (Selbst-/Fremd-)
* [Befragung](https://de.wikipedia.org/wiki/Befragung) (Interviews)
* [Experiment](https://de.wikipedia.org/wiki/Experiment#Psychologie,_Sozialwissenschaften)
* Text- und [Inhaltsanalysen](https://de.wikipedia.org/wiki/Inhaltsanalyse)
* Simulationen (Computermodelle, Szenarien)

Danach möchte man diese Daten **erklären** und interpretieren. Dabei unterscheidet man:
* Explorative Verfahren
* Hypothesen-/Modell-/Theoriegeleitete Verfahren

Bei **[explorativen Verfahren](https://de.wikipedia.org/wiki/Explorative_Datenanalyse)** sucht man nach unbekannten Zusammenhängen in einem Datenpool (z.B. [Data-Mining](https://de.wikipedia.org/wiki/Data-Mining))

Bei **[hypothesengeleiteten Verfahren](https://de.wikipedia.org/wiki/Hypothese#Empirische_Wissenschaften)** steht zu Beginn die Formulierung einer _Theorie_. Daraus leitet man _Hypothesen_ ab und prüft dann die beobachteten Daten inhaltich und/oder statistisch um die Hypothesen zu _verifizieren_ oder _falsifizieren_.

Hat die Theorie sich erhärtet, dann  kann man mit ihrer Hilfe **Vorhersagen**/Prognosen/Gesetze ableiten, deren Gültigkeit davon abhängt, wie "gut" die Theorie ist. In der Psychologie werden Prognosen bezüglich der _Struktur_ (Intelligenz, Persönlichkeit...) und der _Dynamik_ (Entstehung psychischer Störung, Entwicklungsprozesse...) getroffen.

Auf Basis dieser Vorhersagen können wir Verhalten auch **verändern**. Methoden dafür sind u.a.
* Beobachtung/Befragung (Selbstreflektion, Problematisierung, ...)
* Beratung
* Training
* Aufklärung/Bildung
* Therapie

Am Beispiel der Nikotinsucht:
* _beschreiben_: Hirnaktivität bei Nikotinsucht
* _erklären_: Dopamin-Belohnung
* _vorhersagen_: Maßnahmen zur Reduktion von dopaminerger Hyperaktivität führen zu geringerem Rauchkonsum (vorhersagen)
* _verändern_: Neurofeedback Training

# Wissenschaftstheorie

Im Alltag erwerben wir Wissen bewusst oder unbewusst auch aus **nicht-wissenschaftlichen** Quellen:
* Autoritätspersonen
* Religion
* Tradition
* Gesunder Menschenverstand
* Intuition
* Anekdotische Evidenz
* Logik
Für eine detailliertere Ausführung nicht-wissenschaftlicher Quellen (siehe dazu auch Tabelle 1.1 auf Seite 6 in Döring & Bortz (2016) oder auf Folie 26 der Vorlesungsfolien vom 06.10.2020).

Nicht-wissenschaftliche Quellen können zutreffend sein und sich als
nützlich erweisen, aber ihre Aussagen variieren, sind widersprüchlich, von Interessen geleitet und es bleibt unklar, wie man zu dieser Aussage gekommen ist und auf welche Beobachtungen und Daten sie sich stützt.

Abgegrenzt davon ist [Wissenschaftstheorie](https://de.wikipedia.org/wiki/Wissenschaftstheorie) ein Teilgebiet der Philosophie und beschäftigt sich mit Fragen über den wissenschaftlichen Erkenntnisgewinn. Ob und wie dieser möglich ist, welche Einflüsse darauf wirken und welche Rolle Ethik dabei spielen soll. Dabei handelt es sich um ein aktives Forschungsfeld, das an sich selbst den Anspruch stellt keine endgültigen ("in Stein  gemeißelten") Ergebnisse zu produzieren. Sie unterscheidet zwei grundlegende Herangehensweisen: die _Induktion_ und die _Deduktion_.

**[Induktion](https://de.wikipedia.org/wiki/Induktion_(Philosophie))** ist das Schlussfolgeren von einzelnen Beobachtungen auf ein verallgemeinertes Gesetz. Man sammelt Daten, sucht nach Mustern und leitet davon eine Erkenntnis ab. [David Hume](https://de.wikipedia.org/wiki/David_Hume#Induktion) meint jedoch, dass über Induktion kein Erkenntnisgewinn möglich sei, weil die Beobachtungen der Vergangenheit rational betrachtet keinerlei Aussage über die Zukunft träfen. Mit dem selben Argument ließen sich daher nicht einmal Wahrscheinlichkeiten ableiten. (z.B. erwacht man jeden Morgen -> daraus abzuleiten, dass man auch in Zukunft jeden Morgen aufwachen würde, wäre falsch, da man ja irgendwann stirbt). Humes Diskussion dazu wird auch [Induktionsproblem](https://de.wikipedia.org/wiki/Induktionsproblem) genannt. Tatsächlich muss der Mensch aber Induktion anwenden und in diesem Sinne aus der Erfahrung lernen. Aus einem praktischen Standpunkt aus betrachtet ist das durchaus nutzbringend zu bewerten. Dennoch ist diese Praxis unter dem Vernunftsgesichtspunkt für Hume irrational ([Quelle: Wikipedia](https://de.wikipedia.org/wiki/David_Hume#Induktion)). Induktion ist im Forschungsprozess trotzdem wichtig um damit Ideen für Gesetzmäßigkeiten zu finden, auch wenn sie dadurch weder geprüft noch erhärtet (geschweige denn bewiesen) werden können (Hussy et al., 2013, p.8)

**[Deduktion](https://de.wikipedia.org/wiki/Deduktion)** ist das Schlussfolgern vom Allgemeinen (einer Theorie) auf das Spezielle (Beobachtung). Widerspricht eine Beobachtung der Theorie, dann ist diese widerlegt. Stimmt sie überein, dass ist die Theorie bekräftigt, aber nie endgültig bestätigt. Man kann Theorie somit nicht beweisen, aber man kann sie erhärten und falsifizieren.

Hier setzt auch der **[Kritische Rationalismus](https://de.wikipedia.org/wiki/Kritischer_Rationalismus)** von [Karl Popper](https://de.wikipedia.org/wiki/Karl_Popper) an. Demnach sind Theorien nicht etwas, das man beweisen soll, sondern Vermutungen/Vorschläge, die man versuchen soll zu falsifizieren (_Falsifikationsprinzip_). Aus ihnen leitet man dann _Hypothesen_ ab, die durch empirische Beobachtungen widerlegt werden sollen. Das geht nur dann, wenn man Theorien und Hypothesen so aufstellt, dass sie _falsifizierbar_ sind, wodurch sich die Wissenschaft von der Nicht-Wissenschaft abgrenzt (_Poppers Abgrenzungskriterium_), wobei man _"fasifizierbar"_ nicht mit _"falsifiziert"_ verwechseln darf.

Der Forschungsprozess ist daher:
* Theoriebezug und Forschungshypothesen
* Diskussion der getroffenen Vorannahmen
* Berücksichtigung des Forschungsstandes
* systematische Erhebung, Aufbereitung und Analyse von empirischen Daten
zum Forschungsproblem unter Einhaltung wissenschaftlicher Gütekriterien:
 * angemessenes Untersuchungsdesign
 * geeignete Untersuchungsinstrumente
 * aussagekräftige Stichprobe
 * begründete Datenerhebungs-, -aufbereitungs- und -analysemethoden
* Vorgehen gemäß Prinzipien der der Wissenschaftsethik (Manipulationen,
Risiken für VersuchsteilnehmerInnen, Aufklärung & Einwilligung,...)
* schriftliche Dokumentation des Forschungsprozesses und Archivierung
des Datenmaterials zwecks Nachvollziehbarkeit und Nachprüfbarkeit
* wissenschaftliche Veröffentlichung der Studie nach fachkundiger
Begutachtung (Peer-Review)

Dieser Prozess soll nachvollziehbar und reproduzierbar (prüfbar) sein. Viele Befunde der Vergangenheit haben sich gerade in der Psychologie als [nicht reproduzierbar](https://de.wikipedia.org/wiki/Reproduzierbarkeit_(Psychologie)) herausgestellt, weshalb zunehmend gefordert wird in der Forschung dem _[Open Science](https://de.wikipedia.org/wiki/Open_Science)_ Ansatz zu folgen, der als Zusammenspiel von _[Open Source](https://de.wikipedia.org/wiki/Open_Source), [Open Access](https://de.wikipedia.org/wiki/Open_Access)_ und _[Open Data](https://de.wikipedia.org/wiki/Open_Data)_ verstanden wird.

![Open Science als Zusammenspiel von Open Data, Open Access und Open Source](/assets/img/openscience.svg)


# Überprüfung psychologischer Ideen

Einen groben, typischen Ablauf einer Studie kann man wie folgt skizzieren:

![Ablauf einer Studie: Forschungsfrage diskutieren - Hypothese formulieren - Signifikanzniveau festlegen -Stichprobe wählen - Daten erheben - Statistisch auswerten - Hypothese verwerfen/akzeptieren](/assets/img/studie.svg)


## Hypothesen

**Hypothesen** sollen folgenden Kriterien genügen:
* widerlegbar/falsifizierbar durch empirisch überprüfbare Sachverhalte
* widerspruchsfrei und präzise
* begründet und nachvollziehbar
* Operationalisierbarkeit der verwendeten Begriffe
* generalisierend und theoriegeleitet

 In der Regel sollen Hypothesen vor der Datenerhebung formuliert werden (_Prüfexperimente_). Eine Ausnahme sind _Erkundungsexperimente_ bei denen Hypothesen nach der Datenerhebung aufgestellt werden (Hussy et al., 2013, p.34).

Es gibt mehrere **Hypothesenarten**, wobei Hussy et al. (2013, p.32) folgende herausstreichen:
* Universell
* Beschränkt universell
* Quasiuniversell

Weil man in der Psychologie Hypothesen eigentlich nie zu 100% widerlegen kann, ist die _quasiuniverselle Hypothese_ von besonderer Bedeutung. Sie postuliert Regelmäßigkeiten aber toleriert gleichzeitig auch Ausnahmen. Eine Beispielhypothese ist _"Wenn beim Lösen von Problemen
Pausen gemacht werden, dann ist die Lösungsgüte zumeist besser, als wenn keine Pausen
gemacht werden"_. Sie ist somit eine Wahrscheinlichkeitsaussage und ist nicht schon durch eine einzige, sondern erst durch eine signifikante Anzahl gegenteiliger Beobachtungen falsifiziert.

Eine Hypothesen kann auf unterschiedlichen **Hypothesenebenen** formuliert werden. Sobald man eine Hypothese empirisch prüfen möchte, z.B. durch ein Experiment, muss man die darin verwendeten Begriffe operationalisieren. So wird aus einer _theoretisch-inhaltlichen_ eine _empirisch-inhaltliche_ Hypothese, welche man in einem nächsten Schritt statistisch vorhersagbar formuliert. Abschließend bildet man daraus die Alternativ- bzw. **Arbeitshypothese H<sub>1</sub>** (es gibt einen Effekt) und Null- bzw. **Gegenhypothese H<sub>0</sub>** (es gibt keinen Effekt), die sich gegenseitig ausschließen.

![Hypothesenebenen mit Beispielen](/assets/img/hypothesenebenen.svg)

Da wir laut _Kritischem Rationalismus_ Erkenntnisgewinn nur durch Falsifizieren erlangen können, müssen wir versuchen die Nullhypothese zu falsifizieren, um zu beweisen, dass es überhaupt einen Effekt gibt, und um somit unsere Arbeitshypothese zu stärken (ähnlich der Unschuldsvermutung vor Gericht). Hypothesen können _gerichtet_ ("etwas ist besser/schlechter") oder _ungerichtet_ ("es gibt einen Unterschied") sein.

## Wahrscheinlichkeiten

Da wir in der Psychologie mit _quasiuniversellen Hypothesen_ arbeiten, kann nicht ausgeschlossen werden, dass wir bei deren Prüfung falsch liegen. Auch wenn wir beim Untersuchungsdesign, -durchführung und -analyse alles richtig machen, kann z.B. der Zufall dazu führen, dass wir eine Hypothese fälschlicherweise falsifizieren bzw. erhärten:

Beim **α-Fehler** (Fehler 1. Art) hat man die Nullhypothese H<sub>0</sub> fälschlicherweise falsifiziert. Man glaubt, dass es einen Effekt gibt, obwohl es ihn in Wirklichkeit nicht gibt.

Beim **β-Fehler** (Fehler 2. Art) hat man die Nullhypothese fälschlicherweise nicht falsifizieren können. Man geht davon aus, dass es _keinen_ Effekt gibt, obwohl es in Wirklichkeit einen gibt.

In der Regel haben α-Fehler weitreichendere Folgen als β-Fehler.

"Unter **Population** ([Grundgesamtheit](https://de.wikipedia.org/wiki/Grundgesamtheit)) versteht man in der Psychologie die Menge aller potenziellen Untersuchungsobjekte für eine gegebene Fragestellung." (Hussy et al., 2013, p.118)

"Unter einer **[Stichprobe](https://de.wikipedia.org/wiki/Stichprobe)** versteht man eine Teilmenge aus einer Grundgesamtheit, die
unter bestimmten Gesichtspunkten (gemäß der Fragestellung) ausgewählt wurde." (Hussy et al., 2013, p.118)<br>
Eine Stichprobe ist _[repräsentativ](https://de.wikipedia.org/wiki/Repr%C3%A4sentativit%C3%A4t)_, wenn sie das Wesen und die spezifischen Eigenarten der Population gut und verhältnismäßig abbildet. Das ist abhängig von der _Stichprobenstrategie_ und der _Stichprobengröße_. Strategisch wählt man die Stichprobe möglichst _[zufällig](https://de.wikipedia.org/wiki/Zufallsstichprobe#Probleme_der_Zufallsziehung)_ aus, was in der Praxis gar nicht so einfach (z.B. Wahlbefragungen, Telefonumfragen...) und auch kostenintensiv (z.B. Medikamentenstudien bei Schwangeren) ist.

Die **[Deskriptive Statistik](https://de.wikipedia.org/wiki/Deskriptive_Statistik)** beschreibt die gesammelten Daten:
* Organisation der Daten (Matrix, Kodierung, Skalentypen: Nominal-, Ordinal-, Intervall-, Verhältnisskala)
* Darstellung der Daten (Histogramm, Boxplot, Kreisdiagramm...)
* Beschreibung der Daten (Häufigkeiten, Mittelwert, Median, Varianz...)
* Standardisierung von Daten für Vergleiche

Mittels der **[Inferenzstatistik](https://de.wikipedia.org/wiki/Mathematische_Statistik)** leitet man Schlüsse von der Stichprobe auf die zugehörige Population ab. "Aussagen der Inferenzstatistik gehen damit über das Beobachtbare hinaus und sind mit Unsicherheit behaftet." (Hussy et al., 2013, p.179)

Bei Aussagen über die Stichprobe werden lateinische und für Aussagen über die Population griechische Symbole verwendet:

|Wert|Stichprobe|Population|
|---|:---:|:---:|
|Mittelwert|x&#x0304;|μ|
|Standardabweichung|s|σ (sigma)|
|Varianz|s²|σ²|

Eine Stichprobe ist nie "perfekt" repräsentativ, wodurch ihre _Generalisierbarkeit_ eingeschränkt, das Schließen von der Stichprobe auf die Population mit Fehlern behaftet ist und sie somit nur zu einer _geschätzten Wahrscheinlichkeit_ als Ergebnis führt. Bezogen auf unsere Hypothese H<sub>0</sub>, die wir zu falsifizieren versuchen, bedeutet das, dass wir die H<sub>0</sub> nur auf Basis dieser geschätzten Wahrscheinlichkeit ablehnen können. Welche Wahrscheinlichkeit ist nun "gerade noch groß genug", damit wir das dürfen? Dieses _Falsifikationskriterium_ wird im **[statistischen Hypothesentest (Signifikanztest)](https://de.wikipedia.org/wiki/Statistischer_Test)** formalisiert:<br>
"Das zentrale Ergebnis eines Signifikanztests ist die sog. Überschreitungswahrscheinlichkeit _p_. Diese ist die Wahrscheinlichkeit, dass ein gefundenes Stichprobenergebnis oder ein noch stärker von der H<sub>0</sub> abweichendes Ergebnis zustande kommt, falls die H<sub>0</sub> in der Population gilt...Per Konvention gelten Werte für _p_ von weniger als 0,05 (5%) oder 0,01 (1%) als so gering, dass die Nullhypothese verworfen wird." (Hussy et al., 2013, p.180)

Je nach Fragestellung und Hypothese kommen unterschiedliche Methoden der Inferenzstatistik zum Einsatz (Details dazu dann in _VO Einführung in quantitative Methoden_):
#TODO: WBS Diagramm machen
* Dependenzanalyse
 * Unterschiede
   * zentrale Tendenz
     * unabhängige Stichproben
     * verbundene Stichproben
   * Proportion/Häufigkeiten
     * Binomialtest
     * ...
   * Varianzen
     * Chi²
     * ...
 * Zusammenhänge
   * Korrelation
   * einfache Regression
   * ...
* Interdependenzanalyse
 * Faktorenanalyse
 * Clusteranalyse
 * ...

# Einführung in die empirische Forschung - Daten sind das neue Gold

Psychologie ist eine **[empirische Wissenschaft](https://de.wikipedia.org/wiki/Empirie#Empirische_Wissenschaften)**. Sie erklärt das Erleben und Verhalten von Menschen basierend auf Erfahrungen und mit systematischer und methodischer _Datenerhebung_ und _Datenauswertung_. Innerhalb der empirischen Wissenschaften unterscheiden wir Sozial-, Natur- und Technikwissenschaften. Im Gegensatz dazu stehen Nicht-empirische Wissenschaften wie die Formal- und Geisteswissenschaften:

![Gegenüberstellung nicht-empirischer und empirischer Wissenschaften](/assets/img/wissenschaften.svg)

Die Psychologie bedient und überschneidet sich in ihren Forschungsprozessen mit anderen Disziplinen:
* Medizin (Diagnostik, Psychotherapie...)
* Biologie (Neurowissenschaften, Physiologie...)
* Physik (Bildgebung, Messinstrumente...)
* Informatik (Datenverarbeitung...)
* Mathematik (Wahrscheinlichkeit, Statistik...)
* Philosophie (Wissenschaftstheorie...)
* Ökonomie (Entscheidungsverhalten...)
* Soziologie (Umwelteinflüsse...)
* ...

Um aus der komplexen Wirklichkeit verarbeitbare Einheiten für die Forschung abzuleiten, erstellt man **[Modelle](https://de.wikipedia.org/wiki/Modell)**, also vereinfachte Abbilder der Realität. Das Problem dabei ist, dass zu einfache Modelle wichtige Aspekte der Wirklichkeit vermissen und zu komplexe Modelle ihren Zweck der einfachen Verarbeitbarkeit nicht erfüllen: "Alles Einfache ist falsch, alles Komplizierte unbrauchbar." ([Paul Valéry](https://de.wikipedia.org/wiki/Paul_Val%C3%A9ry), siehe auch [Bonini-Paradox](https://de.wikipedia.org/wiki/Bonini-Paradox))

## Untersuchungsdesigns

Eine zentrale Rolle und auch mit erheblichen Aufwand verbunden ist das Erheben von Daten. Dabei bedienen sich empirische Wissenschaften, hier insbesondere die Psychologie u.a. folgender **Datenerhebungsmethoden**:
* Beobachtung
* Interview
* Fragebogen
* Psychologischer Test
* Physiologische Messung
* Dokumentenanalyse
* ...

Damit die erhobenen Daten und folglich auch die gesamte Studie eine ernstzunehmende Aussagekraft besitzt, ist es wichtig ein angemessenes **[Untersuchungsdesign](https://de.wikipedia.org/wiki/Forschungsdesign)** zu wählen und umzusetzen. Untersuchungsdesigns sind weder genormt noch standardisiert. Sie müssen je nach Fragestellung und vorhandenen Resourcen entworfen werden. Dabei sind u.a. folgende Abwägungen zu treffen:
* Vor- und Nachteile
* Ökonomischer Aufwand (z.B. Textanalyse vs. [RCT](https://de.wikipedia.org/wiki/Randomisierte_kontrollierte_Studie)-Psychotherapie)
* Umsetzbarkeit (z.B. Verfügbarkeit von Versuchspersonen)
* Ethik
* ...

Das Untersuchungsdesign lässt sich anhand mehrerer Dimensionen bestimmen:
* Quantitativ / qualitativ / mixed methods
* Labor- / Feldstudie
* Experiment / Quasi-Experiment / Nicht-Experiment
* Quer- / Längsschnittstudie

### Quantitative Methoden, Qualitative Methoden und Mixed-methods

Quantitative und qualitative Designs stehen nicht (mehr) im Widerspruch zu einander, sondern ergänzen sich je nach Forschungsstrategie und Fragestellung.

**[Quantitativen Methoden](https://de.wikipedia.org/wiki/Quantitative_Sozialforschung)** haben die Ideen des kritischen Rationalismus (siehe oben) als wissenschaftstheoretische Grundlage, nämlich Theorien mittels Deduktion und dem Versuch der Falsifikation zu prüfen. Den erhobenen Merkmalsausprägungen werden dabei Zahlen zugeordnet, die dann statistisch geprüft und ausgewertet werden. Nicht allen Forschungsfragen kann man sich quantitativ nähern. Vor allem bei jenen über das _Erleben_ der Menschen stoßen quantitative Methoden an ihre Grenzen.

**[Qualitative Methoden](https://de.wikipedia.org/wiki/Qualitative_Sozialforschung)** basieren auf einem interpretativen Paradigma, [Sozialkonstruktivismus](https://de.wikipedia.org/wiki/Sozialkonstruktivismus), [Hermeneutik](https://de.wikipedia.org/wiki/Hermeneutik), [Dialektik](https://de.wikipedia.org/wiki/Dialektik), [Phänomenologie](https://de.wikipedia.org/wiki/Ph%C3%A4nomenologie)... . Merkmalsausprägungen werden verbal beschrieben. Aufgrund ihres _induktiven_ Charakters dienen sie der Theorien- und Hypothesenkonstruktion, besonders in jungen, noch unerforschten Forschungsfeldern. Das Vorgehen ist zirkulär und bewusst weniger strukturiert. Anpassungen am Vorgehen sind während der Untersuchung möglich (Untersuchungszyklen). Es wird mit kleinen Samples und Einzelfällen (statt mit großen, repräsentativen Stichproben) geforscht. Erhebungsverfahren sind nicht oder nur teils standardisiert (da Daten verbal beschrieben statt numerisch erfasst werden). Dabei spielt Kommunikation und Kooperation zwischen Forschenden und Beforschten eine wesentliche Rolle und des kommt zur Beeinflussung des Forschungsgegenstands durch die Untersuchungungssituation, weshalb die Forschenden bei der Interpretation der Daten auf ein hohes Maß an _Reflexivität_ achten sollten (Hussy et al., 2013, p.192). Qualitative Methoden sind vielseitig und werden flexibel an den Forschungsgegenstand angepasst (Hussy et al., 2013, p.186). Folgende Grafiken zeigen eine Gegenüberstellung der Forschungsprozesse dieser zwei Ansätze:

|Quantitative Studie|Qualitative Studie|
|---|---|
|![Ablauf einer qualitativen Studie](/assets/img/quantitative_studie.svg)|![Ablauf einer qualitativen Studie](/assets/img/qualitative_studie.svg)|

#TODO qualitative Studie Prozess schön zeichnen

"_**[Mixed-Methods](https://en.wikipedia.org/wiki/Multimethodology)**_ bezeichnet eine Forschungsmethode, die eine Kombination von Elementen qualitativer und quantitativer Forschungstraditionen beinhaltet, typischerweise (aber nicht notwendig) innerhalb einer Untersuchung." (Hussy et al., 2013, p.290)

Das können sein:
* Vorstudienmodell: Qualitative Studie zur Hypothesengenerierung und darauf folgend quantitative Studie zur Hypothesenprüfung
* Vertiefungsmodell: Quantitative Studie und darauf folgend qualitative Studie mit ausgewählten Teilnehmern
* Innerhalb einer Studie mehrere Methoden, z.B. Datenerhebung mit qualitativer und quantitativer Methoden

### Labor- und Feldstudie

Die **[Laborstudie](https://de.wikipedia.org/wiki/Laborstudie)** ermöglicht eine künstliche & gut kontrollierbare Untersuchungssituation. Je nach Messinstrument und Fragestellung ist das Labor  alternativlos (z.B. Bildgebungsexperimente, Auswirkungen von Marihuana auf das Fahrverhalten...)

Vorteile:
* gut standardisierbar: gezielte Manipulation der unabhängigen Variablen
* höherer interne Validität, durch Minimieren der Störvariablen (umwelt- bzw. untersuchungsbedingt z. B. Raumtemperatur, Möblierung, anwesende Personen, Geräuschpegel...)
* Einsatz komplexer Messinstrumente

Nachteile:
* reduzierte externe Validität (Künstlichkeit des Untersuchungsortes erschwert Übertragbarkeit der Befunde auf den Alltag)
* Höherere Aufwand für die Probanden
* Höherere Aufwand & Kosten für die Forschenden (Laborraum, Laborpersonal, Gerätschaften...


Bei der **[Feldstudie](https://de.wikipedia.org/wiki/Feldstudie)** findet die Untersuchung im natürlichen Umfeld des Forschungsgegenstandes statt, wodurch Untersuchungsbedingungen den Alltagsbedingungen ähnlich sind.

Vorteile:
* Höhere externe Validität (Generalisierbarkeit)

Nachteile:
* Störvariablen weit weniger kontrollierbar

"Die **interne Validität** eines Experiments ist gegeben, wenn Veränderungen in der AV ausschließlich auf die Variation der UV zurückgeführt werden können." (Hussy et al., 2013, p.137)<br>
Sie ist ein Maß des kausalen Zusammenhangs (Ursache-Wirkungs-Relation) und ist umso höher umso besser Störvariablen minimiert/eliminiert werden konnten. Auch abhängig von Stichprobenziehung, da interpersonelle Unterschiede der Vpn Störvariablen sein können (z.B. kulturelle Unterschiede) → [Randomisierung](https://de.wikipedia.org/wiki/Randomisierung) bzw. [Parallelisierung](https://de.wikipedia.org/wiki/Matching_(Statistik)) (Hussy et al., 2013, p.124)

"Die **externe Validität** eines Experiments ist gegeben, wenn die Ergebnisse der Untersuchung übertragbar sind. Dabei sind drei Aspekte zu unterscheiden, nämlich die Populationsvalidität, die Situationsvalidität und die Variablenvalidität." (Hussy et al., 2013, p.137)<br>
Sie steigt mit der Repräsentativität der Stichprobe und mit Nachweis des Effekts in unterschiedlichen Stichproben und Kontexten (systematische Replikationsstudien)

### Experiment, Quasi-Experiment und Nicht-Experiment

"Unter einem **[Experiment](https://de.wikipedia.org/wiki/Experiment#Psychologie,_Sozialwissenschaften)** (Laborexperiment, Feldexperiment) versteht man die systematische Beobachtung einer abhängigen Variablen unter verschiedenen Bedingungen einer unabhängigen Variablen bei gleichzeitiger Kontrolle der Störvariablen, wobei die zufällige Zuordnung von Probanden und experimentellen Bedingungen gewährleistet sein muss."  (Hussy et al., 2013, p.120)<br>
Das Ziel des Experiments ist die Prüfung von Hypothesen, die einen kausalen Zusammenhang postulieren. Dabei werden zwei Gruppen gebildet: die _Experimentalgruppe_ und die _Kontrollgruppe_. Durch zufällige Zuordnung der Vpn zu den Gruppen (Randomisierung) soll die Vergleichbarkeit der Gruppen gewährleistet werden. Danach werden durch _experimentelle Variation_ die Untersuchungsbedingungen der Gruppen systematisch variiert und die abhängige Variable (AV) gemessen. So eine Anordnung nennt man auch [Randomized controlled trial (RCT)](https://de.wikipedia.org/wiki/Randomisierte_kontrollierte_Studie).

Von einem **[Quasi-Experiment](https://de.wikipedia.org/wiki/Quasi-Experiment)** spricht man, wenn man die Vpn den Gruppen nicht zufällig zuordnen kann (z.B. Studie über den Einfluss von Lernapps auf den Lernerfolg bei Schülern). Dadurch kommt es zu Auswahlverzerrungen (=Störeffekt). Durch Parallelisierung und Matching kann man Störvariablen besser kontrollieren. Die Einteilung in Gruppen, die experimentelle Variation und das Messen der AV sind wie beim Experiment. Das Quasi-Experiment dient ebenfalls der Prüfung von Kausalhypothesen, jedoch mit geringerer interner Validität.

Im Gegensatz dazu kann man mit dem **Nicht-Experiment** _keine_ Kausalhypothesen prüfen, weil man die Untersuchungsbedingungen nicht experimentell variieren kann und somit die interne Validität sehr gering bzw. nicht vorhanden ist. Ebenso gibt es keine randomisierte Zuordnung von Vpn zu Gruppen. Mit Hilfe des Nicht-Experiments lassen sich Unterschieds-, Zusammenhang- und Veränderunshypothesen prüfen. Gründe für die Anwendung dieser Methode statt eines Experiments sind _forschungsökonomischer_ (z.B. geringere Kosten) und _forschungsethischer_ (Drogen, Rauchen, Gewalt...) bzw. praktischer Natur (z.B. Auswirkungen einer Naturkatastrophe), wenn eine experimentelle Variation nicht möglich oder nicht vertretbar wäre. Ein Vorteil ist, dass sich durch den Wegfall der Kausalbeziehung ein breiteres Spektrum von Variablen untersuchen lassen.<br>
Häufig werden auf Basis von Nicht-Experimenten fälschlicherweise kausale Zusammenhänge angenommen (z.B. Höhere Sterblichkeit in Spitälern am Wochenende, Gewaltbereitschaft und Ego-Shooter...)

### Querschnitt- und Längsschnittstudie

**[Querschnittstudien](https://dorsch.hogrefe.com/stichwort/querschnittuntersuchung)** vergleichen eine oder mehrere Stichproben zu _einem_ Zeitpunkt. Weit verbreitet, weil günstiger in der Durchführung, aber Gefahr der [Konfundierung](https://dorsch.hogrefe.com/stichwort/konfundierung) aufgrund von [Kohorteneffekten](https://de.wikipedia.org/wiki/Kohorte_(Sozialwissenschaft).

**[Längsschnittstudien](https://dorsch.hogrefe.com/stichwort/laengsschnittuntersuchung)**
messen und vergleichen _ein und dieselbe_ Stichprobe zu mehrerer Zeitpunkten innerhalb eines Zeitraums. Werden z.B. in der klinischen Psychologie in Form von pre-, post- und follow-up Messungen eingesetzt um die Auswirkung von Interventionen beurteilen zu können. Nachteile sind Sequenzeffekte, die sich bei Messwiederholungen zeigen (Hussy et al., 2013, p.120). Das können Störvariablen sein, wie z.B. die Lebenssituation der Vpn, äußere Einflüsse (Wirtschaftslage), sowie Lern- und Gewöhnungseffekte bei den Messungen und andere mehr.

### Primär-, Sekundärstudie & Metaanalyse

In einer **Primärstudie** erheben die Forscher die Daten selbst. Sie werten die Daten erstmalig aus und haben volle Kontrolle über Forschungsdesign, Stichprobenziehung und  Datenerhebungsmethode. Deshalb sind sie kostenintensiv.

Bei der **Sekundärstudie** werten Forscher bereits aus anderen Studien vorhandene Daten aus um andere (verbesserte) Analysemethoden anzuwenden und/oder um eine andere Fragestellung zu analysieren.

Vorteile:
* kostengünstiger, da Datenerhebung wegfällt
* Datenbanken mit umfassenden Datensätzen (Open Science)

Nachteile:
* keine Kontrolle über Datenqualität und -umfang
* Verfügbarbkeit der Originaldaten (je nach Primärstudie) eingeschränkt

**[Metaanalyse](https://dorsch.hogrefe.com/stichwort/metaanalyse)**

Operationalisierung
Variablen
Merkmalsausprägung diskret vs. stetig , manifest vs. latent, abhängig vs. unabhängig


## Operationalisierung

# Literatur
